---
tags: 
comment: true
---
# 开始学习

## 评分指标

### 分类指标

常见的分类指标包含错误率、精度、准确度（precision，也称查准率）、召回率（recall，也称为查全率）、F1-score、ROC曲线、AUC和对数损失（logloss）

### 错误率和精度

错误率是分类结果错误的样本占样本总数的比例，精度则是分类结果正确的样本数占样本总数的比例。即，$错误率 = 1 - 精度$

### 准确率和找回率

以二分类为例：

|      |      | 真实类别|        |
| :--: | :--: | :------: | :--: |
|      |      | 1 | 0 |
| 预测类别 | 1 | True Positive (TP) | False Positive (FP) |
|      | 0 | False Negative (FN) | True Negative (TN) |

这个的基本逻辑是，对模型预测出来的概率值给定一个阈值。若概率值超过阈值，则预测为 1 （positive，正类），否则预测为 0 （Negative，负类）

- TP ：预测类别为 1 ，真实类别为 1 ，预测为真
- FP ：预测类别为 0 ，真实类别为 1 ，预测为假
- TN：预测类别为 0 ，真实类别为 0 ，预测为真
- FN：预测类别为 1 ，真实类别为 1 ，预测为假

准确率$P$是指被分类器判定为 **正类** 的样本中真正的正类样本所占的比重，换句话说，就是在分类器划分为 正类样本 中 **真正的** 正类样本的占比
$$
P = \frac{TP}{TP + FP}
$$

> 但是存在问题，如果只做一个单独的正样本预测，并且预测类别都是正确，那么通过这个公式得到的就只是100%的正确率
>
> 这很明显没有什么意义

所以这引出了另外一个指标 **召回率（recall）**

召回率是指被分类器正确判定的正类样本占总的正类样本的比重，即所有正类样本中有多少被分类器判别为正类样本
$$
R= \frac{TP}{TP + FN}
$$
准确率和召回率代表了分类器性能的两个方面，单依靠其中一个并不能较为全面地评价一个分类器的性能

> 准确率越高，召回率越低
>
> 反之亦然

### F1-score

为了能够平衡准确率和召回率，便有了F1-score这个指标
$$
F1-score = 2 \times \frac{P \times R}{P + R}
$$

### ROC曲线

ROC曲线用于绘制不同分类阈值时的TP率和FP率。降低分类阈值会导致更多的样本被归为正类别从而增加假正例和真正例的个数。

降低分类阈值会导致更多的样本被划分为正类别，从而增加假正例和真正例的个数。

## 样本选择

影响结果的四个主要原因：

1. 数据集过大严重影响模型的性能
2. 噪声和异常数据导致准确率不高
3. 样本数据冗余或不相关数据没有给模型带来收益
4. 正负样本分布不均匀导致数据存在倾斜

